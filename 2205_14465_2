ByteComp: Revisiting Gradient Compression in Distributed Training

Abstract
Gradient compression (GC) is a promising approach to ad- dressing the communication bottleneck in distributed deep learning (DDL). However, it is challenging to find the opti- mal compression strategy for applying GC to DDL because of the intricate interactions among tensors. To fully unleash the benefits of GC, two questions must be addressed: 1) How to express all compression strategies and the corresponding interactions among tensors of any DDL training job? 2) How to quickly select a near-optimal compression strategy? In this paper, we propose ByteComp to answer these questions. It first designs a decision tree abstraction to express all the compression strategies and develops empirical models to timeline tensor computation, communication, and compres- sion to enable ByteComp to derive the intricate interactions among tensors. It then designs a compression decision al- gorithm that analyzes tensor interactions to eliminate and prioritize strategies and optimally offloads compression to CPUs. Experimental evaluations show that ByteComp can improve the training throughput over the start-of-the-art compression-enabled system by up to 77% for representa- tive DDL training jobs. Moreover, the computational time needed to select the compression strategy is measured in milliseconds, and the selected strategy is only a few percent from optimal.

1 Introduction
Deep Neural Networks (DNNs) have brought remarkable suc- cess to domains such as computer vision [24, 41, 61, 64] and natural language processing (NLP) [20, 31, 39, 66]. Because todayâ€™s training jobs with a single GPU typically take days and even weeks [17, 45], data-parallel distributed deep learn- ing (DDL) has become the norm to accelerate the training with multiple GPUs [3, 27, 34, 35, 59].
However, there exists an exacerbating tension between computation and communication in DDL. The recent innova- tions of hardware accelerators [37, 46] and domain-specific software optimization [15, 16, 76] have dramatically reduced the computation time of DNN training. For example, the single-GPU iteration time of ResNet50 has seen a 22Ã— de- crease in the last seven years [63]. This trend leads to more frequent gradient synchronization in DDL and puts higher pressure on the network. However, it is difficult for GPU cloud network deployments to match this pace; network bandwidth has grown only by roughly 10Ã— in the same pe- riod [40, 46, 49, 57, 79].
The growing concern of communication bottlenecks in DDL has motivated numerous works, such as priority-based scheduling [23, 25, 50], wait-free back-propagation mech- anism [35, 74], and optimized aggregation algorithms [17, 27, 59]. However, even with the latest highly-optimized BytePS [27] which incorporates these state-of-the-art approaches, com- munications for gradient synchronization still account for 42% and 49% of the total training time of GPT2 [51] and BERT-base [20] with 64 NVIDIA V100 GPUs in 8 machines connected by a 100Gbps Ethernet network.
Gradient compression (GC) algorithms [5, 6, 29, 36, 58, 62, 70, 71] have a great potential to address the communication bottlenecks in DDL by saving up to 99.9% of the gradient exchange while preserving the training accuracy and conver- gence [26, 62, 72]. However, the training speedups of DDL with GC are only modest because of the costly compression operations. For example, applying GC to the aforementioned GPT2 training only achieves a 1.15Ã— speedup. This moti- vates us to revisit GC from the system perspective to fully unleash its benefits for DDL.
Applying GC to a DNN model entails many decisions for each tensor, such as whether to compress, the type of compute resources for compression and the communication schemes for compressed tensors. DDL typically involves both communications inside a machine and across machines. Therefore, another decision is whether to apply GC to intra- or inter-machine communication or both. The compression strategy, i.e., the decisions for all tensors, determines the training throughput of compression-enabled DDL.
Unfortunately, it is very challenging to make these deci- sions because of the intricate interactions among tensors. Therefore, the first research question we have to answer to unleash the benefits of GC is how to express all possible compression strategies and the corresponding interactions among tensors for any DDL training job? Because of the extremely large search space, even if all the strategies and the interactions are available, the time to find the optimal one can be prohibitive. Hence, the second research question is how to analyze the interactions among tensors to quickly select a near-optimal compression strategy?
In this paper, we propose ByteComp to answer these two questions in order to maximize the benefits of GC. We make the following contributions.
â€¢ We develop a decision tree abstraction for the compression strategy and empirical models for the time of tensor com- putation, communication, and compression to answer the the first question. The abstraction can express all possible compression options of any tensors regardless of different tensor sizes and GC algorithms. Based on the abstraction, ByteComp can express all compression strategies of any DDL training jobs. The empirical models enable ByteComp to de- rive the timeline of tensor computation, communication, and compression of all tensors in a DNN model, and thus their intricate interactions with any compression strategy.
â€¢ We propose a compression decision algorithm for quickly selecting a near-optimal compression strategy to answer the second question. ByteComp analyzes the interactions among tensors to eliminate a large number of suboptimal compression strategies. Based on the analysis, ByteComp proposes a prioritization method for applying GC to tensors to maximize the benefits, and considers the overlapping time among tensor computation, communication, and compres- sion to make compression decisions for each tensor. Because of different performance trade-offs of GPUs and CPUs for GC, ByteComp finds a provably optimal solution to offload compression from GPUs to CPUs to minimize the resource contentions with tensor computation.
â€¢ We implement a fully featured system for ByteComp. We implement both GPUs and CPUs compression libraries. We also implement communication libraries to support different communication schemes in both intra- and inter-machine communications. Experimental evaluations demonstrate that with 64 GPUs, ByteComp can improve the training through- put by up to 269% compared with BytePS. It also outper- forms the state-of-the-art compression-enabled system (i.e., HiPress [9]) by up to 77% across representative DNN training jobs. Moreover, the computational time needed by ByteComp to select the compression strategy is measured in millisec- onds, and the performance difference between the selected strategy and the optimal strategy is only a few percent.

2 Background
2.1 Communication in DDL
In data-parallel distributed deep learning (DDL), each GPU has a replica of the DNN model. The training dataset is 
divided into multiple partitions and each GPU takes one par- tition. Training is performed in multiple iterations. At the beginning of an iteration, each GPU consumes a mini-batch of training data from its own partition. It then independently performs forward propagation and backward propagation to generate gradient tensors, which can be aggregated syn- chronously or asynchronously among GPUs. Synchronous data-parallel DDL, where all GPUs communicate the gradi- ent tensors and wait for the aggregated results prior to the next iteration, is the de facto standard used by DDL frame- works [3, 27, 35, 59]; asynchronous data-parallel DDL, where GPUs do not wait for aggregation to complete, can hurt the model accuracy [13]. We focus on synchronous data-parallel DDL because of its wide adoption.
Because DDL typically employs multiple machines and each machine has multiple GPUs, it involves both intra- machine and inter-machine communication. Hierarchical communication (as shown in Figure 1) is widely applied in DDL frameworks [14, 27, 35, 59] because the intra-machine network is usually faster than the inter-machine network. There are three phases for gradient synchronization in hier- archical communication: 1) the gradients are first aggregated among GPUs within one machine; 2) they are then aggre- gated across machines; and 3) the aggregated gradients are communicated within one machine again to ensure that all GPUs have the same synchronized results. Flat communi- cation, i.e., all GPUs join the same collective operation and have only one communication phase, is also supported in some frameworks [35, 59].
2.2 Computation and Communication Tension
Because of the layered structure and a layer-by-layer com- putation pattern in DNN models [10], the wait-free back- propagation mechanism (WFBP) [14, 27, 35, 59, 74] is widely adopted to overlap communication with computation in DDL to reduce the iteration time.
However, there still exists an exacerbating tension be- tween computation and communication. The recent advance- ments in ML hardware accelerators [46] and specialized software stacks [15, 55, 76] have significantly improved the single-GPU training speed. For instance, the single-GPU it- eration time of ResNet50 has seen a 22Ã— decrease in the last seven years [63]. Faster training speed leads to more fre- quent gradient synchronization and higher demands on the network. Unfortunately, network upgrades have not kept up with the pace of computation-related advancements. The network bandwidth in GPU clouds has only seen a roughly 10Ã— increase in the same period [40, 46, 49]. This imbal- ance between the fast-growing computing capability and the slower-growing communication bandwidth reduces the chance to overlap communication with computation, and results in poor scalability of DDL.
To illustrate, we trained real-world DNN models on BytePS- 0.2.5 [27], a highly-optimized DDL framework, with 64 NVIDIA V100 GPUs (8 GPUs per machine) and a 100Gbps inter-
machine Ethernet network. We measure the scaling fac-
ğ‘‡ğ‘›
ğ‘›ğ‘‡
tor [21, 75], which is defined as
throughput of a single device and ğ‘‡ğ‘› is the throughput of DDL with ğ‘› devices. BytePS only achieves the scaling factors of 0.58 and 0.51 for the training of two representative and popular DNN models, GPT2 and BERT-base, with NVLink 2.0 for GPU-to-GPU interconnection, as shown in Table 1. To put this into context, the training time of BERT-base is about 1200 GPU hours under ideal linear scaling [47], but in practice, it will take 2350 GPUs hours with 64 GPUs due to the communication time caused by gradient synchroniza- tion. Thus, DNN practitioners have to spend nearly twice the amount of money on training because the cost linearly increases with the required GPU hours [8].
When network bandwidth in GPU clouds has not kept pace with the improvements in computation, an alternative is to shrink the communicated traffic volume by applying gradient compression.
2.3 Gradient Compression
Many gradient compression (GC) algorithms have been pro- posed in the machine learning community. Sparsification and Quantization are the two main types of GC algorithms. Sparsification selects a subset of the original stochastic gra- dients for synchronization [5, 36, 62] and it can save up to 99.9% of the gradient exchange while maintaining model accuracy [36]. Quantization decreases the precision of gra- dients; gradients in single-precision floating-point format (FP32) are mapped to fewer bits, such as 8 bits [19], 2 bits [71], and even 1 bit [11, 29, 58] to reduce the communicated traf- fic volume by up to 96.9%. Such compression algorithms have been theoretically proven and/or empirically validated to preserve the convergence of model training and impose negligible impact on model accuracy when combined with error-feedback mechanisms [26, 36, 58, 62, 72]. The industry is adopting GC because of its great potential to alleviate the communication bottleneck in DDL. The efforts from Meta, AWS, and ByteDance to bring GC to mainstream DNN sys- tems have begun recently [7, 44, 78]. However, the scalability improvement of DDL via GC has been still poor.
3 Challenges of Applying GC to DDL
We first define some key terms.
â€¢ Tensor computation is the computation of a tensor dur- ing backward propagation.
â€¢ Communication time is the wall-clock time for commu- nication. It is denoted as ğœğ‘ğ‘œğ‘šğ‘š .
â€¢ Communication overhead is the communication time that cannot overlap with tensor computation of any tensors. It is denoted as ğ‘œğ‘ğ‘œğ‘šğ‘š .
â€¢ Compression time is the wall-clock time to perform compression and decompression operations on devices, e.g., GPUs or CPUs. It is denoted as ğœğ‘ğ‘œğ‘šğ‘
â€¢ Compression overhead is the compression time that can- not overlap with either tensor computation or communica- tion of any tensors. It is denoted as ğ‘œğ‘ğ‘œğ‘šğ‘ .
Although GC can reduce ğœ , its compression over- ğ‘ğ‘œğ‘šğ‘š
heads can dramatically dilute the benefits gained from the reduced communication time. To demonstrate this, we apply a popular sparsification algorithm, DGC [36], to the afore- mentioned GPT2 training and a representative 1-bit quan- tization algorithm, EFSignSGD [29], to BERT-base training. The compression rate of DGC is 1%, i.e., only 1% of gra- dients are exchanged during synchronization. Tensors are compressed with GPUs [9] or CPUs [78] in separate exper- iments. As shown in Table 1, GC only achieves up to 20% training speedup, which is on par with the findings in prior works [4, 9, 73]. In fact, GC can harm performance in some situations. To illustrate, we apply DGC with 1% compres- sion rate to the training of LSTM [41] on 64 V100 GPUs with PCIe 3.0 x16 as the intra-machine network and 25Gbps
1
inter-machineEthernet. AslistedinTable1,GCslowsdown
training by up to 9%.
In the following, we will explain the root reasons why it
is challenging to obtain large benefits from GC for DDL.
3.1 Root Reasons of the Challenges
The choice of compression strategies determines the iteration time of compression-enabled DDL. Figure 2 is an example that shows the timelines of tensor computation, communi- cation, and compression of DDL with different compression strategies. Figures 2(a) is the baseline without GC and it il- lustrates the tensor computation time (blue boxes) and com- munication time (green boxes) of all tensors, i.e., T0, T1, and T2. Figure 2(b) compresses T2 with GPUs and it reduces the iteration time. Figures 2(c) and (d) compress the three tensors with GPUs and CPUs, respectively, but unfortunately, they both harm the performance of DDL. Figures 2(e) shows the optimal compression strategy with ByteComp.
It is challenging to find the optimal compression strategy. Applying GC to DDL is essentially to reduce the communi- cation overheads at the cost of the compression overheads. The optimal compression strategy maximizes the difference between the reduced communication overheads and the in- curred compression overheads. There are three root reasons for the challenges.
Reason #1. It is hard to quantify the communication and compression overheads because of the intricate interactions among tensors.
Communication may or may not overlap with ten-
sor computation. The overlapping time of different tensors
can vary. For example, in Figure 2(a), T â€™s ğ‘œ is zero be- 0 ğ‘ğ‘œğ‘šğ‘š
then compresses the aggregated tensor and obtains ğ‘‡ğ‘– ğ‘— for the second communication op.
cause its communication is fully overlapped with tensor computation, but T â€™s ğ‘œ is its communication time be-
2 ğ‘ğ‘œğ‘šğ‘š
cause it has no overlap with tensor computation. Moreover,
the overlapping time of one tensor can vary under different compressionstrategies.Forexample,inFigure2(a),T â€™scom-
munication partially overlaps with T â€™s tensor computation.
However, in Figure 2(c), after compression, T â€™s communica-
tion can completely overlap with T â€™s tensor computation.
Furthermore, in Figure 2(d), T â€™s communication has no
overlap with the computation of other tensors. Hence, it is difficult to quantify the communication overhead of each tensor.
Compression may or may not overlap with tensor
computation and communication. How much ğœğ‘ğ‘œğ‘šğ‘ can
be overlapped highly depends on the strategy. For instance, in Figure 2(b), T â€™s GPU compression fully overlaps with T â€™s communication. In Figure 2(d), T â€™s CPU compression par-
tially overlaps with T â€™s tensor computation. In Figure 2(c),
the three GPU compressions are fully exposed. Hence, it is difficult to quantify the compression overhead.
Only considering ğœğ‘ğ‘œğ‘šğ‘š and ğœğ‘ğ‘œğ‘šğ‘ for the decision of compression strategies can harm the performance. Fig- ure 2(c) maximizes the difference between the reduced com- munication time and the compression time by compressing the three tensors. However, because GPU compression com- petes for compute resources with tensor computation, it de- lays training and prolongs the iteration time instead. Hence, we must consider ğ‘œğ‘ğ‘œğ‘šğ‘š and ğ‘œğ‘ğ‘œğ‘šğ‘ to determine compression strategies for compression-enabled DDL.
Reason #2. It is hard to choose the right communication schemes for compressed tensors because of Reason #1.
There are two types of communication schemes for compressed tensors: indivisible schemes and divisible schemes. We first consider the case that there are ğ‘ machines in DDL and each machine has a single GPU. An indivisible scheme has only one communication operation, as shown in Fig- ure 3. Once a tensor is compressed, each node (e.g., GPU or CPU) broadcasts its compressed tensor to other nodes. After communication, each node decompresses these com- pressed tensors and aggregates them. In contrast, a divisible scheme has two communication operations, as shown in Figure 4. Tensors are first compressed and partitioned into ğ‘› parts, where 1 â‰¤ ğ‘› â‰¤ ğ‘ . The ğ‘—ğ‘¡h node receives the ğ‘—ğ‘¡h part from other nodes. It then performs decompression, aggre-
2 gation,andthesecondcompressionoperation. Afterthat,
it broadcasts the compressed tensor to other nodes. After communication, each node decompresses these compressed tensors and aggregates them.
It is hard to decide between indivisible and divisible
schemes for GC. Compared to indivisible schemes, divisible
schemes have lower communication time and higher com-
pression time due to the two compression and decompression
operations. As shown in Figures 5(a), GC with a divisible
scheme outperforms GC with an indivisible scheme. How-
ever, in Figure 5(b), T â€™s communication overlaps with T â€™s
01
tensor computation and an indivisible scheme outperforms a divisible scheme for GC. Thus, the decision of communica- tion schemes depends on the interactions among tensors.
Reason #3. It is hard to determine whether to apply GC to intra- or inter-machine communication or both to alleviate communication bottleneck because of Reasons #1 and #2.
DDL can involve both intra- and inter-machine com- munications. We now consider the case that there are ğ‘ machines and each machine has ğ‘˜ GPU, where ğ‘˜ > 1, as shown in Figure 1. It has intra- and inter-machine communi- cations, and both can become the performance bottleneck.
Whether to apply GC to intra- or inter-machine com-
munication or both depends on the interactions among
tensors. If a tensor is only compressed for inter-machine
communication, intra-machine communication can still be
a performance issue. Figure 5(c) shows that applying GC to
intra-machine communication can further reduce the itera-
tion time. However, if T1 has a longer computation time, it
can overlap more time with T â€™s communication, as shown
in Figure 5(d). In this case, applying GC to both intra- and inter-machine communications leads to worse performance than applying it to inter-machine communication alone.
This decision also depends on the chosen commu- nication schemes. Because both intra- and inter-machine communications need to choose from indivisible or divisi- ble schemes, the difficulties to determine the right schemes make the decision of the compression choices even harder.

3.2 Research Questions
In light of the three root reasons, there are two research questions to answer for applying GC to DDL.
Question #1: how to express all possible compres- sion strategies and interactions among tensors for DDL regardless of different distributions of computation and communication time of tensors in different DNN models, different intra- and inter-machine bandwidth, and different GC algorithms?
Applying GC to a tensor must answer the following fun- damental questions: Does it need compression? If so, what type of compute resources to use for its compression? After compression, what communication schemes should the com- pressed tensor use? If it has multiple communication phases, where to compress and decompress this tensor? The search space is huge when holistically considering these decisions. Moreover, there are typically a large number of tensors in a DNN model and the compression option of one tensor can impact the choices of other tensors because of their intri- cate interactions. The compression strategy determines the interactions among tensors, which determine the training throughput of compression-enabled DDL. Therefore, it is crucial to express all the strategies and the corresponding interactions among tensors to avoid missing the opportunity to maximize the training throughput.
Question #2: how to analyze the interactions among tensor computation, communication, and compression, as well as the different performance trade-offs of GPUs and CPUs for GC, to determine a near-optimal com- pression strategy for DDL and to do so quickly?
Even if all compression strategies are at hand, the time complexity to find the optimal strategy is exponential (Â§4.4.1). The searching time can be much longer than the training time, which is unacceptable. Moreover, the optimal strategy is specific to each situation depending on the DNN model, intra- and inter-machine bandwidth, GC algorithm, etc., and thus cannot be reused across situations. A successful solution to this question must develop new insights on the interac- tions among tensors and the different performance trade-offs with different types of compute resources for GC that can eliminate suboptimal strategies from consideration.

4 The Design of ByteComp
4.1 Overview
To maximize the training throughput of compression-enabled DDL, the core idea of ByteComp is to select a near-optimal compression strategy from an extremely large search space with the following two techniques.
A decision tree abstraction to describe all compression options of any tensors as well as empirical models for the time of tensor computation, communication, and compression to express all compression strategies and interactions among tensors. The abstraction can express all types of compute resources for compression, communi- cation schemes, and different choices to apply GC to intra- and inter-machine communications. It can also serve as the building block to describe all the compression strategies of any compression-enabled DDL. The empirical models en- able ByteComp to derive the timeline of tensor computation, communication, and compression of all tensors, and thus their intricate interactions with any compression strategy. An algorithm for selecting a near-optimal compres- sion strategy with four properties. The algorithm 1) rules out tensors that certainly bring no benefits to DDL with GC based on the analysis of interactions among tensors; 2) uses a prioritization method for applying GC to tensors to maxi- mize the benefits with the minimum number of tensors for compression; 3) determines the compression options with the compression and communication overheads based on the analysis of interactions, rather than with the wall-clock time; and 4) finds a provably optimal solution to offload compression from GPUs to CPUs.
4.2 The Decision Tree Abstraction
4.2.1 The dimensions of the search space. There are four dimensions that ByteComp must consider to describe the search space of compression options for each tensor. The decision tasks for these dimensions are shown in Figure 6. Dimension 1: compression or no compression. Because GC can incur non-negligible compression time and even harm performance, there is no need to compress all tensors. ByteComp must determine the set of tensors that should be compressed to maximize the benefits of GC.
Dimension 2: GPU or CPU for compression. Both GPUs and CPUs can be used for GC to minimize the compression overhead. ByteComp must determine the set of tensors in a DNN model for GPU and CPU compression, respectively. Task Comp and Task Decomp, as listed in Table 3, are the action tasks to decide between GPUs and CPUs for compres- sion and decompression operations, respectively. Dimension 3: the communication schemes. Compressed tensors cannot use Allreduce for synchronization because their aggregation operations are not associative [4, 9, 73]. Both indivisible and divisible communication schemes can be used, while each can have more than one choice of collec- tive routines, i.e., one collective communication operation or an operation pair. Table 2 lists the common collective rou- tines used in DDL for GC [1, 35, 65]. Because tensors can be communicated without GC, Table 2 lists the collective rou- tines for uncompressed tensors as well. We distinguish the two communication operations in a divisible scheme as its first and second steps. In addition, flat and hierarchical com- munications lead to a different number of communication phases for gradient synchronization. Therefore, this dimen- sion requires ByteComp to consider three sub-dimensions: flat or hierarchical communication, indivisible or divisible schemes, and specific collective routines for each communi- cation phase. The decision tasks of the three sub-dimensions are shown in Figure 6 as flat comm?, divisible scheme?, and which comm?. Because both uncompressed and compressed tensors have indivisible and divisible schemes, and division schemes have two collective operations, which comm? has six action tasks, as listed in Table 3.
Dimension 4: the compression choice. It determines where to perform compression and decompression operations. For flat communication, it has two communication patterns be- cause it can choose from an indivisible or a divisible scheme. For hierarchical communication, it can choose from a divisi- ble or an indivisible scheme for its inter-machine communi- cation. Although it can also choose from a division scheme or two indivisible schemes for its two intra-machine commu- nications, the former is better than the latter due to the less amount of traffic volume. Therefore, ByteComp only consid- ers division schemes for intra-machine communications in hierarchical communication. Tensors can be compressed as long as they need communication and compressed tensors can be decompressed after any communication operation. All the options for this dimension, i.e., the possible positions of Task Comp and Task Decomp in each communication pattern, are illustrated in Figure 7.
4.2.2 Constructing the tree. A compression option is a se- ries of decision tasks that determine all the communication and compression operations of a tensor for its synchroniza- tion. These operations have orders and dependencies. There are eight action tasks (as listed in Table 3), but not all of them can have direct connections, i.e., a task is performed right after another. The valid connections of action tasks are omitted due to space limitations.
Tree construction. Based on the four dimensions and the valid connections of the eight action tasks, ByteComp can express all possible compression options of any tensor with a decision tree, as shown in Figure 7. Because the choices of GPUs or CPUs for Task Comp and Task Decomp do not impact communication tasks, we use one arrow to represent their two choices for simplicity.
There are three pruning rules to construct the tree. The first rule is that the following action tasks of an action task must be its valid connections. The second rule is that the communication tasks must match the correct steps. For ex- ample, Comm1 and Comm1ğ‘ğ‘œğ‘šğ‘ are only valid as the first steps of divisible schemes. The third rule is that the choices of communication tasks in the first and second steps must pair. For example, if Comm1 is Alltoall, then Comm2 in this divisible scheme must be Allgather. Each path from Start to End is a valid compression option. The red crosses in Figure 7 are the invalid paths ruled out by these pruning rules.
There are five sub-trees illustrated in Figure 7 to abstract parts of the tree. Sub-tree ğ‘‡1 and ğ‘‡2 describe the process of the second intra-machine step with the input tensor uncom- pressed and compressed, respectively. Sub-tree ğ‘‡3 and ğ‘‡4 describe the process of inter-machine communication plus the second intra-machine step with the input tensor uncom- pressed and compressed, respectively. Sub-tree ğ‘‡5 describes the process of the second inter-machine step plus the second intra-machine step with the input tensor uncompressed. Expressiveness and extensibility. Because all the valid connections between decision tasks have been considered, this decision tree abstraction can cover all the possible com- pression options. It is easy for ByteComp to extend the search space of communication tasks to consider new communi- cation schemes for GC [21, 54] and other types of compute resources [28, 67]. In addition, it allows users to manually add constraints to prune the decision tree to rule out undesir- able compression options for their applications. For example, users can limit the number of compression operations for each tensor to avoid the accuracy loss of training models. Compression strategies. Let T = {ğ‘‡ğ‘– } denote the set of tensors in a DNN model and the number of tensors in T is |T| = ğ‘. C is the set of all possible compression options. ğ‘† = {ğ‘ ğ‘— } is a compression strategy for the DNN model, where ğ‘ğ‘— âˆˆCisthecompressionoptionfortensorğ‘‡ğ‘—.
4.3 Empirical interactions among tensors
The decision tree abstraction can express all compression strategies, but it is incapable of describing the intricate in- teractions among tensors, which determine the choice of compression strategies for different DDL training jobs. To describe the interactions, ByteComp proposes different meth- ods to empirically model the time of tensor computation, communication, and compression, respectively.
Tensor computation. ByteComp needs the computation time of each tensor. It collects execution traces of DNN train- ing jobs without GC for 100 iterations to capture the starting and ending time of the computation of each tensor during backward propagation. ByteComp then averages the compu- tation time. It also collects the information of tensor sizes.
Communication time. ByteComp needs the communica- tion time of tensors with and without GC. Given a tensor, ByteComp predicts its communication time with different communication schemes and network bandwidth. The cost models follow the model analysis in the literature [48, 65]. These communication models account for different tensor sizes, communication schemes, the number of machines and GPUs, and network bandwidth.
Compression time. ByteComp also predicts the compres- sion time of tensors with different sizes and different types of compute resources. Based on the information collected from execution traces, it can have all the possible tensor sizes as the input of compression and decompression operations. For any GC algorithm, ByteComp profiles its computational time of these operations on GPUs and CPUs, respectively. It runs compression and decompression operations with dif- ferent tensor sizes 100 times and then averages the results. We observe that both the tensor computation time and the compression time keep almost constant across runs [63, 75]. Expressing interactions. Given these empirical models and a compression strategy, ByteComp can derive the time- line of tensor computation, communication, and compression of all tensors in a DNN model. Several timeline examples are shown in Figure 2. It can obtain the overlapping time of tensors and thus their interactions based on the timeline.
In the next section, ByteComp will exploit the timeline and analyze the interactions among tensors to obtain a near- optimal compression strategy for compression-enabled DDL.
ByteCompâ€™s Decision Algorithm
The optimization problem. We define the opti- mization problem as follows to search for the optimal com- pression strategy for a DDL training job.
Problem. Given a DDL training job and a compression al- gorithm, how to maximize its training throughput with an optimal compression strategy?
Let ğ¹ (ğ‘† ) be the iteration time with compression strategy ğ‘† . The objective is to minimize ğ¹ (ğ‘† ) with the optimal com- pression strategy. The difficulty of the problem results from the overlapping time among tensor computation, commu- nication, and compression. Given a compression strategy, ByteComp can obtain the overlapping time of each tensor with other tensors. However, both CPU and GPU compres- sion delay communications and change the overlapping time accordingly. Naively, we can enumerate all possible combi- nations to find the optimal solution. This is not acceptable because the time complexity is ğ‘‚(|C|ğ‘ ), where ğ‘ could be a few hundred and |C| is 4341 based on the decision tree abstraction in Figure 7.
4.4.2 ByteCompâ€™s GPU compression. To quickly deter- mine a near-optimal compression strategy for DDL, Byte- Comp first considers GPU resources for GC and then offloads compression to CPUs to minimize the contention with tensor computation. There are three properties for the design of ByteCompâ€™s GPU compression decision algorithm.
Property #1. The communication timeline of a DNN
model can have bubbles, i.e., the gaps between communi-
cations of adjacent tensors. In Figure 8(a), there is a bubble
between the communications of T0 and T1 because T1 is not
ready for communication when T â€™s communication com-
pletes. There is no benefit to compressing tensors communi- cated before bubbles because reducing their communication time only widens the gaps, rather than shifts communica- tions of tensors after bubbles to an earlier time. Compressing these tensors even harms the performance of DDL because of the resource contentions with tensor computation. We observe that half of the tensors are communicated before bubbles in the training of LSTM with 8 NVLink-based GPU machines in a 100Gbps network. Moreover, compressing par- ticular tensors can also lead to new bubbles being formed due to the reduced communication time. For example, Figure 8(b) shows that a new bubble appears when T2 is compressed. Therefore, ByteComp rules out uncompressed tensors com- municated before bubbles for GC whenever the bubbles ap- pear.
Property #2. There are two insights for the compression order of tensors. The first one is that compressing larger tensors can bring more benefits to DDL because GC incurs a constant overhead to launch GPU kernels for compres- sion [59, 69]. Figure 9 shows the ratio of the reduced com- munication time to the incurred compression time with 64 GPUs and NVLink. The ratio increases with tensor sizes and it indicates that GPU compression is more efficient for larger tensors. The second one is that compressing tensors closer to the output layer, i.e., the last layer during backward propaga-
tion, can bring more benefits. For example, in Figure 8(c), T1
and T2 have the same size. Compressing T2 can reduce more iteration time than compression T for two reasons: 1) T â€™s compression overlaps more with communication and has no contention with tensor computation, and 2) compressing T2 can reduce more communication overhead because its com- munication overlaps less with tensor computation. Based on these two insights, ByteComp applies GC to tensors in the descending order of their sizes, and prioritizes tensors closer to the output layer when they have the same size.
Property #3. ByteComp considers the communication and compression overheads to determine the compression options. As discussed in Section 3.1, only considering the communication and compression time for the decisions can harm the performance because they can be overlapped with other operations. Given a tensor, ByteComp enumerates the possible compression options and expresses the corre- sponding interactions among tensors. It then chooses the one which minimizes the iteration time as the compression option.
Algorithm 1 shows ByteCompâ€™s GPU compression deci- sion algorithm to determine the compression option of each tensor in a DNN model. It first sorts and groups tensors with Lines 2-3 (Property #2) and then rules out uncompressed tensors communicated before bubbles with Remove() (Prop- erty #1). Given a tensor ğ‘‡ğ‘–ğ‘‘ğ‘¥ , GetBestOption() enumerates all possible GPU compression options for this tensor and keeps the options of other tensors unchanged (Line 16-20). Then there are |Cğ‘”ğ‘ğ‘¢ | + 1 strategy candidates (one of them is no compression). ByteComp can derive the iteration time of each candidate with the empirical models introduced in Sec- tion 4.3. Line 21 accounts for the interactions among tensors and selects the best candidate with the minimum iteration time (Property #3). After determining the compression op- tion of one tensor, ByteComp checks if new bubbles appear and rules out uncompressed tensors communicated before them again in Line 8 (Property #1).
4.4.3 ByteCompâ€™s CPU offloading. ByteComp offloads
compression from GPUs to CPUs to further improve the
training throughput of DDL after Algorithm 1. Tensors with
no compression are ruled out for CPU offloading and the
set of the left tensors is denoted as T , which can have ğ‘”ğ‘ğ‘¢
hundreds of tensors. The time complexity with brute force for CPU offloading is ğ‘‚(2|Tğ‘”ğ‘ğ‘¢ |). Tensors in Tğ‘”ğ‘ğ‘¢ can have the same compression option, i.e., they take the same com- pression choice and communication schemes. ByteComp takes a greedy algorithm to find a provably optimal com- pression strategy for CPU offloading based on an interesting observation.
Lemma1. Supposeğºisasetoftensorswiththesamesizeand same compression option from Tğ‘”ğ‘ğ‘¢ . Suppose also ğ‘ tensors in ğº must be offloaded to CPUs for compression. The best solution is to offload the ğ‘ tensors farthest from the output layer.
The intuition of Lemma 1 is that offloading tensors to
CPUs earlier can overlap more CPU compression with com-
munication and tensor computation, and thus reduce the
CPU compression overheads. Therefore, if tensors in Tğ‘”ğ‘ğ‘¢
can be grouped like ğº in Lemma 1, there is no need to evalu-
ate all possible combinations because Lemma 1 restricts the
choices of tensors for CPU offloading in each group.
Algorithm 2. ByteComp first groups T to have Gğ‘”ğ‘ğ‘¢ = ğ‘”ğ‘ğ‘¢
ğ‘”ğ‘ğ‘¢ ğ‘”ğ‘ğ‘¢
ğ‘”ğ‘ğ‘¢ ğ‘”ğ‘ğ‘¢
{ğº1 ,ğº2
,Â·Â·Â· ,ğº
},whereğºğ‘– isasetoftensorswith
ğ‘‘
the same size and the same compression option. The tensors
ğ‘”ğ‘ğ‘¢
in ğºğ‘– are sorted in the descending order of their distances
to the output layer. Denote ğ‘ˆ = {ğ‘¢1,ğ‘¢2, Â· Â· Â· ,ğ‘¢ğ‘‘ }, where ğ‘¢ğ‘– ğ‘”ğ‘ğ‘¢
is the number of tensors in ğºğ‘– for CPU offloading and ğ‘”ğ‘ğ‘¢
0â‰¤ğ‘¢ğ‘– â‰¤|ğºğ‘– |.Uisthesetofallpossibleğ‘ˆ.Foreach
ğ‘ˆ âˆˆ U, ByteComp considers a compression strategy that ğ‘”ğ‘ğ‘¢
offloads the compression of the first ğ‘¢ğ‘– tensors in ğºğ‘– to CPUs, and derives its iteration time. It traverses U to search for the best ğ‘ˆ with the minimum iteration time.
5 Evaluation
     5.1 Experimental Setup
Testbeds. Two testbeds are used: 1) 8 GPU machines with NVLink and a 100Gbps network with TCP/IP, and 2) 8 PCIe- only GPU machines with a 25Gbps network. Each machine has 8 NVIDIA Tesla V100 GPUs (32 GB GPU memory) and 2 CPUs/48 cores (Intel Xeon 8260 at 2.40GHz). Each ma- chine runs Debian 10 and the software environment includes CUDA-11.0, PyTorch-1.8.0, BytePS-0.2.5, and NCCL-2.7.8. Workloads. We use six popular real-world DNN models including three computer vision models (VGG16, ResNet101 and UGATIT) and three NLP models (BERT-base, GPT2, and LSTM) by following the literature [21, 27, 57]. We set the batch sizes of these models by also following the literature [9, 21, 32, 42, 57]. Specifically, the per-GPU batch size is kept constant as the number of GPUs increases, and the batch sizes are modest because large batch sizes are known to cause convergence problems [57, 64]. The details of the models, datasets, and batch sizes are shown in Table 4. Compression algorithms. We use three representative com- pression algorithms: Randomk [62] and DGC [36] for spar- sification (1% compression rate), and EFSignSGD [29] for quantization. Error-feedback [29, 36] is applied on both GPU and CPU compression to preserve the model accuracy. Baselines. We use BytePS [27] as the training baseline with- out GC (FP32). We use HiPress [9] and HiTopKComm [60] as the two baselines with GPU compression, and BytePS- Compress [78] as the baseline with CPU compression. Performance metrics. We use trained images per second as the metric for computer vision models and tokens per second for NLP models. We measure the computational time of ByteComp and training accuracy of DNN models. We also provide the upper bound on the training throughput of compression-enabled DDL (Upper Bound). This is obtained by assuming GC has no compression time and has no impact on tensor computation.
Implementation. We implement a GPU compression li- brary shared by HiPress, HiTopKComm, and ByteComp as well as a CPU compression library shared by BytePS- Compress and ByteComp. We also implement a communica- tion library to support different communication schemes in both intra- and inter-machine communications shared by all baselines and ByteComp. These libraries consist of 5.1K and 3.0K lines of code in C++ and Python. ByteCompâ€™s decision algorithm is implemented with 1.1K lines of code in Python. 5.2 End-to-End Experiments
5.2.1 DDL with NVLink-based GPU machines. Figure 11 shows the training throughput of three DNN models with ByteComp and baselines. The performance bottleneck is inter-machine communication.
As shown in Figure 11a, the compression baselines bring very limited speedups over FP32 for BERT-base. For exam- ple, HiTopKComm and HiPress only outperform FP32 by up to 4% and 13%, respectively. It is because there are a large number of tensors in BERT-base, while none of the baselines consider the interactions among tensors. Their compression strategies lead to costly compression overheads. ByteComp significantly improves the performance over all baselines. For example, with 64 GPUs, it outperforms BytePS-Compress, Hi- TopKComm, and HiPress by 31%, 54%, and 40%, respectively. For GPT2, it outperforms BytePS-Compress and HiPress by 42% and 33% with 64 GPUs, as shown in Figure 11b.
UGATIT is very communication-intensive because of its large model size. When the number of GPUs is 64, the per- formance improvement with HiPress and HiTopKComm is 86% and 66%, respectively, as shown in Figure 11c. BytePS- Compress even harms the performance by 18% due to the costly computational overhead for CPU compression. Byte- Comp leverages both GPUs and CPUs for compression. It outperforms FP32, BytePS-Compress, HiTopKComm, and HiPress by 149%, 205%, 50%, and 35%, respectively. One im- portant observation is that the improvements of ByteComp become larger from 8 GPUs to 64 GPUs. This implies that when DDL scales out, the computational overhead caused by compression also increases, and ByteComp becomes more beneficial.
5.2.2 Computational time of ByteComp. Table 5 lists the computational time of ByteComp to select compression strategies for the training of different DNN models with 8 NVLink-based GPU machines (the results are similar with PCIe-only GPU machines). The time increases with the num- ber of tensors in DNN models, but even for ResNet101 with 314 tensors, the computational time is still within one iter- ation time. In contrast, brute force takes a very long time because it has to traverse all the possibilities. Even though LSTM only has 10 tensors, the searching time is still unac- ceptable.
Table 6 shows the computational time of ByteComp to find
the best CPU offloading solution. After ByteCompâ€™s GPU
compression decision algorithm, the number of tensors for
CPU offloading has been significantly reduced. Brute force
can quickly find the best solution for VGG16 and LSTM,
but it takes a long time for other models. ByteComp can
still quickly find the best solution. For example, there are 54
tensors in BERT-base for CPU offloading, but they only have
a few different tensor sizes, as shown in Figure 10. ByteComp
only needs to consider a few thousand choices to find the
best CPU offloading.
5.2.3 DDL with PCIe-only GPU machines. The perfor-
mance bottlenecks could be both inter- and intra-machine communications in this setup. Figure 12b shows that the three compression baselines bring almost no improvement for LSTM model with GC. For example, HiPress only outper- forms FP32 by up to 2%, and BytePS-Compress even harms the performance by 12% with 64 GPUs. It is because they only compress tensors to reduce inter-machine communi- cation and cannot effectively alleviate the intra-machine communication bottleneck. Moreover, they also incur costly compression overhead. ByteComp compresses tensors to re- duce both inter- and intra-machine communications when necessary and always has the best performance across all cases. For example, with 64 GPUs, it outperforms BytePS- Compress, HiTopKComm, and HiPress by 101%, 73%, 77%, respectively. For VGG16 model with 64 GPUs, the speedups of ByteComp over FP32, BytePS-Compress, and HiPress are 269%, 357%, 55%, respectively.
We observe that ResNet101 is not communication-intensive and it achieves the scaling factor of 0.70 with FP32. Figure 12c shows applying GC to ResNet101 with the compression base- lines can harm its performance. HiTopKComm reduces its training throughput by up to 54% because it compresses all the tensors and leads to exorbitant compression overhead. HiPress also has high over-compression penalties and it de- grades the performance by 4% with 64 GPUs. In contrast, ByteComp still outperforms FP32, BytePS-Compress, and HiPress by up to 20%, 18%, and 24%, respectively.
5.2.4 ByteCompâ€™s compression strategies are near- optimal. We have performed experiments for all combi- nations of GC algorithms (i.e. Randomk, DGC, EFSignSGD), DNN models (i.e. VGG16, ResNet101, UGATIT, BERT-base, GPT2, LSTM), varying the number of GPUs from 8 to 64, over both NVLink and PCIe, across all schemes (i.e. FP32, HiPress, BytePS-Compress, HiTopKComm, Espresso). However, due to space limitations, we present a summary of all the results for the 64-GPU scenario; the raw results will be included in a technical report in the future. Specifically, we present the cu- mulative distribution of the performance differences of each scheme from the Upper Bound. Figure 13a displays the distri- butions of performance differences for all the training with NVLink-based machines and 64 GPUs. The performance dif-ferences between ByteComp and Upper Bound is always less than 10%. To call out a few specific data points, the perfor- mance differences for the training of GPT2 with EFSignSGD, UGATIT with DGC, and BERT-base with Randomk are only 3%, 5%, and 7%, respectively. Note that the differences be- tween ByteCompâ€™s compression strategy and the optimal strategy can be even smaller because Upper Bound is by definition higher than the training throughput of the opti- mal strategy. Figure 13b shows the distributions for all the training with PCIe-only machines and 64 GPUs and Espresso similarly out-performs other baselines.
5.3 Importance of the Entire Search Space
To evaluate the importance of considering all four dimen- sions, we cripple one of the dimensions and then select the compression strategy with the remaining three dimen- sions. We cripple Dimension 1 with two restricted mecha- nisms: All compression: It compresses all tensors. Myopic compression: It does not consider interactions among ten- sors when applying GC to tensors. We cripple Dimension 2 with two restricted mechanisms: GPU compression: It only compresses tensors with GPUs. CPU compression: It only compresses tensors with CPUs. We cripple Dimen- sion 3 with two restricted mechanisms: Inter Allgather: It compresses tensors for inter-machine communication and uses Allgather for compressed tensors. Inter Alltoall: It compresses tensors for inter-machine communication. The communication scheme is Alltoall/Allgather. We cripple Di- mension 4 with Inter Alltoall and another restricted mech- anism Alltoall+Alltoall: It first compresses tensors for the first intra-machine communication and the communication scheme is Alltoall. It then decompresses and compresses tensors again for inter-machine communication. It uses All- toall/Allgather for inter-machine communication and All- gather for the second intra-machine communication.
Figure 14 shows the scaling factors of VGG16 with 64 GPUs. NVLink-based GPU machines are used in (a), (b), and (c), and EFSignSGD is used in (d). The compression strate- gies determined by ByteComp always outperforms the com- pression strategies selected from the cripple search space. Moreover, Figure 14(c) verifies that different types of GC algorithms need different communication schemes, and Fig- ure 14(d) verifies that different intra- and inter-machine band- width need different compression choices.
5.4 Convergence validation
It has been theoretically proven and empirically validated that GC can preserve the training accuracy and conver- gence [9, 21, 26, 36, 58, 62, 72]. In this section, we reaffirm these conclusions and demonstrate that ByteComp can pre- serve the training accuracy and convergence.
We conduct a test following the methodology in [21] to fine-tune BERT-base for the question answering task on SQuAD [52] for two epochs and repeat the experiments ten times. The number of GPUs is 64 on 8 NVLink-based GPU machines. Figure 15a shows that ByteComp with DGC can achieve around 1.55Ã— speedup over no compression (i.e. FP32) and it has almost the same F1 score as no compression. We also train ResNet101 for 120 epochs on ImageNet [18] from scratch and apply EFSignSGD to the model training. As shown in Figure 15b, the speedup of ByteComp over no compression (i.e. FP32) is 1.23Ã—. The achieved Top-1 accuracy with ByteComp is 77.10%, which is very close to the no- compression accuracy of 77.18%.
6 Related Work
GRACE [73] quantitatively evaluates the impacts of GC al- gorithms and observes that GC can incur non-negligible compression overhead, but it does not study or address the challenges of applying GC to DDL. Several frameworks are recently proposed to support compression-enabled DDL. HiTopKComm [60] designs a new communication scheme for GC, but it compresses all tensors with GPUs and leads to prohibitive compression overhead. HiPress [9] proposes compression-aware synchronization to overlap compression with communication and a selective compression mecha- nism to decide whether to compress a tensor, but it only uses GPUs for compression and ignores the interactions among tensors. BytePS [78] also supports GC, but it only uses CPUs for compression and ignores the interactions among ten- sors as well. These frameworks only compress tensors for inter-machine communication. In contrast, ByteComp uses both GPUs and CPUs for compression, analyses interactions among tensors to make compression decisions, and address both intra- and inter-machine communication bottlenecks. OmniReduce [21] introduces block gradient sparsification, which is a new type of GC algorithm, but ByteComp focuses on how to efficiently apply GC to DDL.
Other than GC [5, 6, 11, 12, 29, 36, 58, 70, 71, 77], there are other approaches that aim at improving the training throughput of DDL. SwitchML [57] and ATP [33] exploit programmable switches for gradient aggregations. Other communication schemes have been proposed to more effi- ciently aggregate gradients. For example, BytePS [27] uses spare CPU and bandwidth resources in GPU clouds to optimize both intra- and inter-machine communications. Blink [68] generates optimal communication primitives for intra-machine communication with NVLink. PLink [38] de- signs a hierarchical aggregation scheme for DDL in public clouds, where the machine-to-machine bandwidth is non- uniform due to the hierarchical structure of data centers. ByteScheduler [50], P3 [25], and TicTac [23] schedule com- munications of tensors closer to the output layer with higher priority. These approaches are compression-agnostic; since ByteComp supports compression-enabled DDL, it can be integrated with most of them.
7 Conclusion
ByteComp is a general framework to enable DDL to achieve near-optimal training speed with GC. It holistically consid- ers all the dimensions when making decisions for how to apply GC to DDL. ByteComp can express all the compression strategies and analyze the intricate interactions among ten- sors to quickly select a near-optimal compression strategy for any DDL training job. It outperforms the state-of-the- art compression-enabled systems by up to 77% across six popular DNN models and preserve model accuracy.
